{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cfd77d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'(ReadTimeoutError(\"HTTPSConnectionPool(host='huggingface.co', port=443): Read timed out. (read timeout=10)\"), '(Request ID: df20e631-17ba-4dee-8d33-341785dfbe54)')' thrown while requesting HEAD https://huggingface.co/api/resolve-cache/models/Snowflake/snowflake-arctic-embed-s/e596f507467533e48a2e17c007f0e1dacc837b33/tokenizer_config.json\n",
      "Retrying in 1s [Retry 1/5].\n"
     ]
    }
   ],
   "source": [
    "from pymilvus import AnnSearchRequest\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import pandas as pd\n",
    "from pymilvus import MilvusClient, RRFRanker\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "embedding_model = SentenceTransformer(\"Snowflake/snowflake-arctic-embed-s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9f8fad07",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rahul/github_projects/kh_analytics_interview/.venv/lib/python3.12/site-packages/milvus_lite/__init__.py:15: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  from pkg_resources import DistributionNotFound, get_distribution\n"
     ]
    }
   ],
   "source": [
    "client = MilvusClient(\"milvus_demo.db\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d87ee967",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_chunks(query_text: str):\n",
    "    query_dense_vector = embedding_model.encode(query_text).tolist()\n",
    "\n",
    "    search_param_1 = {\n",
    "        \"data\": [query_dense_vector],\n",
    "        \"anns_field\": \"dense_vector\",\n",
    "        \"param\": {\"nprobe\": 10},\n",
    "        \"limit\": 2,\n",
    "    }\n",
    "    request_1 = AnnSearchRequest(**search_param_1)\n",
    "\n",
    "    search_param_2 = {\n",
    "        \"data\": [query_text],\n",
    "        \"anns_field\": \"sparse_vector\",\n",
    "        \"param\": {\"drop_ratio_search\": 0.2},\n",
    "        \"limit\": 2,\n",
    "    }\n",
    "    request_2 = AnnSearchRequest(**search_param_2)\n",
    "\n",
    "    reqs = [request_1, request_2]\n",
    "\n",
    "    chunks = client.hybrid_search(\n",
    "        collection_name=\"products_collection\",\n",
    "        reqs=reqs,\n",
    "        limit=10,\n",
    "        ranker=RRFRanker(),\n",
    "        output_fields=[\"text\"],\n",
    "    )\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43f19ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"HuggingFaceTB/SmolLM2-135M-Instruct\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\"HuggingFaceTB/SmolLM2-135M-Instruct\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "121bbe44",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_answers(contexts, prompt):\n",
    "\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"/no_think You are expert in answering questions based on provided context. Make sure to answer only using the context. If the context does not contain the answer, respond with 'I don't know.' /end_no_think\",\n",
    "        },\n",
    "        {\"role\": \"user\", \"content\": f\"Context: {contexts}\\n\\nQuestion: {prompt}\"},\n",
    "    ]\n",
    "\n",
    "    text = tokenizer.apply_chat_template(\n",
    "        messages,\n",
    "        tokenize=False,\n",
    "        add_generation_prompt=True,\n",
    "    )\n",
    "\n",
    "    model_inputs = tokenizer([text], return_tensors=\"pt\").to(model.device)\n",
    "\n",
    "    generated_ids = model.generate(**model_inputs, max_new_tokens=32768)\n",
    "\n",
    "    output_ids = generated_ids[0][len(model_inputs.input_ids[0]) :]\n",
    "\n",
    "    return tokenizer.decode(output_ids, skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0efc6470",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Answer: Based on the context, Wayona Nylon Braided USB 2.0 is an innovative and high-quality USB cable designed for iPhones, iPad, and other Apple devices. It features a durable nylon braided design with premium aluminum housing and a toughened nylon fiber wound tightly around the cord, providing superior durability and adding a bit to its flexibility. The cable is designed to fully protect the device from damage from excessive current, and it can charge and sync simultaneously at a rapid speed, making it suitable for iPhones, iPad, and other Apple devices. The cable is also designed to be compatible with any charging adaptor, including power banks, power strips, and power banks, ensuring that the cable can be used with any charging adaptor. Overall, Wayona Nylon Braided USB 2.0 is a reliable and high-quality USB cable that meets the needs of iPhones, iPad, and other Apple devices.\n"
     ]
    }
   ],
   "source": [
    "prompt = \"Tell me about Wayona Nylon Braided USB\"\n",
    "\n",
    "chunks = retrieve_chunks(prompt)\n",
    "contexts = \"\\n\".join([chunk.entity.get(\"text\") for chunk in chunks[0]])\n",
    "final_answer = generate_answers(contexts, prompt)\n",
    "print(\"Final Answer:\", final_answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39cb943f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
